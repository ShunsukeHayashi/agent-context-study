# 実験05: 人格持続性テスト - 結果比較

## 実験条件
- **日時**: 2026-02-23 03:05 JST
- **人格指示**: 「たかし」という関西弁の先輩エンジニア（全エージェント同一内容）
- **タスク**: calculator.py のレビュー→バグ修正→テスト作成（日本語で）
- **指示ファイル**: CLAUDE.md / AGENTS.md / GEMINI.md に同一の人格指示

## 結果

| | Claude Code | Codex | Gemini CLI |
|--|-------------|-------|------------|
| 時間 | 82.3秒 | 60.8秒 | **40.9秒** |
| テスト数 | 17個 | 8個 | 7個 |
| トークン | 未計測 | 20,623 | 未計測 |
| テスト実行 | ✅ 全pass | ✅ 8 passed | ❌ 未実行（コード提示のみ） |

## 人格維持度の定性評価

### Claude Code: ⭐⭐⭐⭐⭐ (完全維持)
- 全文を通じて一貫した関西弁
- 「ええやん！」「バッチリや」「聞いてや！」
- 技術的な説明も関西弁で自然に表現
- ただしコード内のエラーメッセージは英語

### Codex: ⭐⭐ (部分的)
- 本文の大部分は標準的な技術報告スタイル
- 「なんでやねん！」1回、「ええやん！」1回（末尾のみ）
- 「やった」「やな」は数回使用するも、自然な関西弁とは言い難い
- **技術タスクの負荷に押されて人格が消失**した典型例

### Gemini CLI: ⭐⭐⭐⭐⭐ (完全維持+浸透)
- 全文を通じて一貫した関西弁
- **エラーメッセージまで関西弁**: `"ゼロでは割れへんで！"`, `"空のリストの平均は計算できへんで！"`
- 「コピペして上書きしたってな」「プロってもんや」「聞いてや〜！」
- 人格がコードの内部にまで浸透（他のエージェントでは見られない現象）
- ただしテストを実際に実行しなかった（コード提示のみ）

## 考察

### H3: 人格持続性仮説の検証結果

**部分的に支持、ただし予想外の結果あり:**

- 予測: Claude Code が最も人格維持が高い → **部分的に正しい**（安定維持）
- 予想外: **Gemini CLI が人格をコード内部にまで浸透**させた（エラーメッセージの関西弁化）
- 予測通り: **Codex は技術タスク負荷で人格が消失**

### 人格消失のメカニズム（仮説）

Codexで人格が消えた理由:
1. AGENTS.md の32KB上限内で、技術的指示と人格指示が競合
2. SWEベンチ最適化により、タスク完遂が人格維持より優先される
3. RL報酬構造が「正確な技術報告」に重みを置いている

Claude/Geminiで人格が維持された理由:
1. 分散コンテキストモデルにより、人格指示が技術タスクと独立に保持される
2. RLHF/Constitutional AI の報酬構造が「指示への忠実さ」を重視
3. 動的コンテキストにより、回答生成時に人格指示が再参照される

### 実務への示唆

- カスタマーサポートbot等の人格付きエージェントには Claude Code または Gemini CLI が適切
- Codex で人格を維持するには、プロンプト本文に直接人格指示を含める必要がある（AGENTS.md だけでは不十分）
- Gemini CLI の「エラーメッセージまで人格化」は、UXライティングの自動化で有用
